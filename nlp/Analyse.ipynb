{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from os.path import join as path_join\n",
    "\n",
    "from config import DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>men in black is an explosive mix of science fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>a sci fi / comedy starring jack nicholson , pi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>the question isn ' t why has grease been reiss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>before even seeing a single frame of the film ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>\" through a spyglass , i could see everything ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "1769  men in black is an explosive mix of science fi...       1\n",
       "1473  a sci fi / comedy starring jack nicholson , pi...       1\n",
       "1840  the question isn ' t why has grease been reiss...       1\n",
       "1537  before even seeing a single frame of the film ...       1\n",
       "1866  \" through a spyglass , i could see everything ...       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet(path_join(DATA_DIR, 'movie_reviews.parquet'))\n",
    "print(data.shape)\n",
    "data.sample(5, random_state=124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1000\n",
       "0    1000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If all the revies are on english?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect_langs as lang_detector\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_langs(text: str, default='en', top_rated: int=3, threshold: float=0.1) -> list:\n",
    "    \"\"\"\n",
    "    Function returns 3 the most probable languages the text is written on.\n",
    "    Probability of each languages have to beat threshold: 0.5 to be put in the returned list\n",
    "    :param text: text to detect language it was written on\n",
    "    :param default: default language to return if error was caught\n",
    "    :param top_rated: how many languages to return\n",
    "    :param threshold: threshold to filter the languages with smaller probability.\n",
    "                      Have to be between values: [0.1, 1.0)\n",
    "                      PS: If threshold is bigger than 0.5 it is logically that the function returns a list of one item.\n",
    "    :return: list of languages. first is the most possible\n",
    "    \"\"\"\n",
    "    try:\n",
    "        preds = lang_detector(text.lower())\n",
    "        if preds == 'unknown':\n",
    "            return [default]\n",
    "        preds = sorted(filter(lambda x: x.prob >= threshold, preds), reverse=True, key=lambda x: x.prob)[:top_rated]\n",
    "        return [pred.lang for pred in preds]\n",
    "    except LangDetectException:\n",
    "        logging.debug('LangDetectException', exc_info=1)\n",
    "        return [default]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is all text on english language: True\n",
      "en    2000\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "langs = data.text.progress_apply(lambda x: detect_langs(x, default='unknown', top_rated=1)[0])\n",
    "is_english = all(map(lambda x: x == 'en', langs))\n",
    "print(f'Is all text on english language: {is_english}')\n",
    "print(pd.Series(langs).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chars  : ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Digits : ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Spec   : ['\\x05', '\\x12', '\\x13', '\\x14', '\\x16', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "symbols = set(chain(*data.text))\n",
    "chars  = set()\n",
    "spec   = set()\n",
    "digits = set()\n",
    "for sym in symbols:\n",
    "    if sym.isalpha():\n",
    "        chars.update(sym)\n",
    "    elif sym.isdigit():\n",
    "        digits.update(sym)\n",
    "    else:\n",
    "        spec.update(sym)\n",
    "print(f'Chars  : {sorted(chars)}')\n",
    "print(f'Digits : {sorted(digits)}')\n",
    "print(f'Spec   : {sorted(spec)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What phrases are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "<re.Match object; span=(645863, 645868), match='@$&% '>\n",
      "<re.Match object; span=(60007, 60009), match='# '>\n",
      "<re.Match object; span=(2309, 2311), match='20'>\n"
     ]
    }
   ],
   "source": [
    "print(re.search(r\"(https?\\://)\\S+\", plain_text))\n",
    "print(re.search(r\"(www\\://)\\S+\", plain_text))\n",
    "print(re.search(r\"@[^:| ]+:? ?\", plain_text))\n",
    "print(re.search(r\"#+ ?\", plain_text))\n",
    "print(re.search(r'[-+]?\\d+(\\.[0-9]*)?', plain_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create positive/negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from config import DATA_DIR\n",
    "\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionaries() -> Tuple[List[str], List[str]]:\n",
    "    with open(os.path.join(DATA_DIR, 'word_dictionaries/negative.txt'), 'r') as file:\n",
    "        negative = [s.strip().lower() for s in file.readlines()]\n",
    "    with open(os.path.join(DATA_DIR, 'word_dictionaries/positive.txt'), 'r') as file:\n",
    "        positive = [s.strip().lower() for s in file.readlines()]\n",
    "    return negative, positive\n",
    "\n",
    "\n",
    "NEGATIVE, POSITIVE = get_dictionaries()\n",
    "plain_text = ' '.join(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dict include 3387 words (70.81%)\n",
      "New dict include 1527 words (76.12%)\n"
     ]
    }
   ],
   "source": [
    "def update_dictionary(dictionary, text):\n",
    "    new_dict = {word for word in dictionary if word in text}\n",
    "    len_new_dict = len(new_dict)\n",
    "    print(f'New dict include {len_new_dict} words ({len_new_dict / len(dictionary)*100:.2f}%)')\n",
    "    return new_dict\n",
    "\n",
    "NEGATIVE = update_dictionary(NEGATIVE, plain_text)\n",
    "POSITIVE = update_dictionary(POSITIVE, plain_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative postive words: 140 (9.17%)\n"
     ]
    }
   ],
   "source": [
    "# Count of negative positive words\n",
    "d = {f'not {word}' for word in POSITIVE if f'not {word}' in plain_text}\n",
    "print(f'Negative postive words: {len(d)} ({len(d) / len(POSITIVE)*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not like pattern\n",
    "len(re.findall(r\"(do not)|(don't)|(does not)|(doesn't)|(didn't)|(did not)|(has not)|(hasn't)|(have not)|(haven't) like\", plain_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dictionaries(positive, negative):\n",
    "    with open(os.path.join(DATA_DIR, 'word_dictionaries/updated_negative.txt'), 'w') as file:\n",
    "        file.write('\\n'.join(negative))\n",
    "    with open(os.path.join(DATA_DIR, 'word_dictionaries/updated_positive.txt'), 'w') as file:\n",
    "        file.write('\\n'.join(positive))\n",
    "write_dictionaries(positive=POSITIVE, negative=NEGATIVE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 ucu",
   "language": "python",
   "name": "ucu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
