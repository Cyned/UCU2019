{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from os.path import join as path_join\n",
    "\n",
    "from config import DATA_DIR\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n",
      "--------------------\n",
      "Target distribution:\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>the second serial - killer thriller of the mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>my giant begins with a monologue that ' s more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>disney ' s \" air bud \" tells a boy - and - his...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>synopsis : in this movie , steven spielberg , ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>i must admit that i was a tad skeptical of \" g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "205   the second serial - killer thriller of the mon...       0\n",
       "564   my giant begins with a monologue that ' s more...       0\n",
       "750   disney ' s \" air bud \" tells a boy - and - his...       0\n",
       "1013  synopsis : in this movie , steven spielberg , ...       1\n",
       "1897  i must admit that i was a tad skeptical of \" g...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet(path_join(DATA_DIR, 'movie_reviews.parquet'))\n",
    "print(data.shape)\n",
    "print('-' * 20)\n",
    "print(f'Target distribution:\\n{data.target.value_counts(normalize=True)}')\n",
    "data.sample(5, random_state=32421)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import my_metric\n",
    "\n",
    "from timeit_ import timeit_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_name(model):\n",
    "    return type(model).__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models.linear_regression import LinearModel\n",
    "from models.lgbmachine import LGBMachine\n",
    "from models import get_lgb, get_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "##### Some  experiments with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB:  81.85%\n",
      "Time execution:\t4.91sec\n",
      "------------------------------\n",
      "LogisticRegression:  84.75%\n",
      "Time execution:\t5.94sec\n",
      "------------------------------\n",
      "LinearSVC:  84.00%\n",
      "Time execution:\t8.50sec\n",
      "------------------------------\n",
      "SGDClassifier:  79.60%\n",
      "Time execution:\t5.02sec\n",
      "------------------------------\n",
      "CPU times: user 28.5 s, sys: 112 ms, total: 28.6 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for classifier in [MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134)]:\n",
    "    model = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', classifier),\n",
    "    ])\n",
    "    with timeit_context('Time execution'):\n",
    "        print(f'{model_name(classifier)}:  {my_metric(classifier=model)*100:.2f}%')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg + hyperparameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.09s/it, best loss: -0.842]\n",
      "Get best linear model:\t42.14sec\n",
      "LinearModel 81.90%\n",
      "Time execution:\t6.18sec\n"
     ]
    }
   ],
   "source": [
    "with timeit_context('Get best linear model'):\n",
    "    classifier = get_linear(x_train=vectorizer.fit_transform(data['text']).toarray(), y_train=data['target'].values)\n",
    "    \n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier),\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(classifier)} {my_metric(classifier=model)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer tuning\n",
    "Metrics:\n",
    "- 84.65%\n",
    "- 85.00%\n",
    "- 83.90%\n",
    "- 84.15%\n",
    "- 83.95%\n",
    "- 83.75%\n",
    "- 79.70%\n",
    "- 85.00%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from preprocessing import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  85.00%\n",
      "Time execution:\t1min 53.54sec\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = CountVectorizer(\n",
    "    lowercase     = True, \n",
    "    tokenizer     = lambda text: Tokenizer(stem='stem', splitter=None, remove_spec=True).tokenize(text), \n",
    "    stop_words    = stopwords,\n",
    "    ngram_range   = (1, 2),\n",
    "    analyzer      = 'word',\n",
    "    max_df        = 1.0,\n",
    "    min_df        = 1,\n",
    "    max_features  = 10000,\n",
    ")\n",
    "\n",
    "char_vectorizer = CountVectorizer(\n",
    "    lowercase     = True, \n",
    "    tokenizer     = None, \n",
    "    ngram_range   = (3, 5),\n",
    "    analyzer      = 'char',\n",
    "    max_df        = 0.95,\n",
    "    min_df        = 10,\n",
    "    max_features  = 1000,\n",
    ")\n",
    "\n",
    "classifier = LogisticRegression(random_state=123142)\n",
    "model = Pipeline([\n",
    "#     ('vectorizer', FeatureUnion([('word', word_vectorizer), ('char', char_vectorizer)])),\n",
    "#     ('vectorizer', char_vectorizer),\n",
    "    ('vectorizer', word_vectorizer),\n",
    "    ('classifier', classifier),\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(classifier)}:  {my_metric(classifier=model)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it, best loss: -0.827]\n",
      "Get best linear model:\t33.20sec\n",
      "LinearModel 82.20%\n",
      "Time execution:\t1min 50.20sec\n"
     ]
    }
   ],
   "source": [
    "with timeit_context('Get best linear model'):\n",
    "    classifier = get_linear(x_train=word_vectorizer.fit_transform(data['text']).toarray(), y_train=data['target'].values)\n",
    "    \n",
    "model = Pipeline([\n",
    "    ('vectorizer', word_vectorizer),\n",
    "    ('classifier', classifier),\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(classifier)} {my_metric(classifier=model)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF/IDF\n",
    "##### Some experiments with TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB:  80.85%\n",
      "Time execution:\t4.66sec\n",
      "------------------------------\n",
      "LogisticRegression:  82.00%\n",
      "Time execution:\t5.06sec\n",
      "------------------------------\n",
      "LinearSVC:  85.70%\n",
      "Time execution:\t5.28sec\n",
      "------------------------------\n",
      "SGDClassifier:  84.70%\n",
      "Time execution:\t5.03sec\n",
      "------------------------------\n",
      "CPU times: user 22.1 s, sys: 68.4 ms, total: 22.2 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for classifier in [MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134)]:\n",
    "    model = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', classifier),\n",
    "    ])\n",
    "    with timeit_context('Time execution'):\n",
    "        print(f'{model_name(classifier)}:  {my_metric(classifier=model)*100:.2f}%')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg + hyperparameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.49s/it, best loss: -0.852]\n",
      "Get best linear model:\t25.79sec\n",
      "LinearModel 85.65%\n",
      "Time execution:\t5.47sec\n"
     ]
    }
   ],
   "source": [
    "with timeit_context('Get best linear model'):\n",
    "    classifier = get_linear(x_train=vectorizer.fit_transform(data['text']).toarray(), y_train=data['target'].values)\n",
    "    \n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier),\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(classifier)} {my_metric(classifier=model)*100:.2f}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase    = True,\n",
    "    tokenizer    = lambda text: Tokenizer(stem='stem', splitter=None, remove_spec=True).tokenize(text), \n",
    "    analyzer     = 'word', \n",
    "    ngram_range  = (1, 2),\n",
    "    max_df       = 0.8,\n",
    "    min_df       = 10, \n",
    "    max_features = 100000,\n",
    "    norm         = 'l2',\n",
    "    use_idf      = True,\n",
    "    smooth_idf   = True,\n",
    ")\n",
    "\n",
    "classifier = LogisticRegression(random_state=123142)\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier),\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(classifier)}:  {my_metric(classifier=model)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.57it/s, best loss: -0.8470000000000001]\n",
      "Get best linear model:\t28.71sec\n",
      "LinearModel 86.30%\n",
      "Time execution:\t2min 2.28sec\n"
     ]
    }
   ],
   "source": [
    "with timeit_context('Get best linear model'):\n",
    "    classifier = get_linear(x_train=vectorizer.fit_transform(data['text']).toarray(), y_train=data['target'].values)\n",
    "    \n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier),\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(classifier)} {my_metric(classifier=model)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is it usefull to use blending of baselines model in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x360 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['text'], data['target'], test_size=0.25, random_state=314)\n",
    "\n",
    "f,(ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, figsize=(25, 5))\n",
    "\n",
    "for classifier, ax in zip([MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134)],\n",
    "                     [ax1, ax2, ax3, ax4]):\n",
    "    model = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', classifier),\n",
    "    ])\n",
    "    model.fit(x_train, y_train)\n",
    "    sns.heatmap(confusion_matrix(y_true=y_test, y_pred=model.predict(x_test)), \n",
    "                annot=True, annot_kws={\"size\": 10}, fmt=\"d\", ax=ax).set_title(model_name(classifier))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It seems blending should not work, but whatever less try\n",
    "- 85.65% (LogReg)\n",
    "- 86.35% (LGB)\n",
    "- 86.40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import BlendingFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyned/anaconda3/envs/ucu/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "/home/cyned/anaconda3/envs/ucu/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "/home/cyned/anaconda3/envs/ucu/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier:  84.45%\n",
      "Time execution:\t1min 54.45sec\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase    = True,\n",
    "    tokenizer    = lambda text: Tokenizer(stem='stem', splitter=None, remove_spec=True).tokenize(text), \n",
    "    analyzer     = 'word', \n",
    "    ngram_range  = (1, 3),\n",
    "    max_df       = 0.8,\n",
    "    min_df       = 2, \n",
    "    max_features = 100000,\n",
    ")\n",
    "\n",
    "blending_features = BlendingFeatures([\n",
    "    MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134, loss='hinge'),\n",
    "])\n",
    "        \n",
    "final_classifier = lightgbm.LGBMClassifier(random_state=123142, n_jobs=-1)\n",
    "        \n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', blending_features),\n",
    "    ('predictor', final_classifier)\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(final_classifier)}:  {my_metric(classifier=model)*100:.2f}%')\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RuleBased model\n",
    "- 56.00%\n",
    "- 65.50%\n",
    "- 70.10%\n",
    "- 68.35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models.rule_based import RuleBased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuleBased 68.35%\n",
      "Time execution:\t2min 15.81sec\n"
     ]
    }
   ],
   "source": [
    "classifier = RuleBased()\n",
    "\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(classifier)} {my_metric(classifier=classifier)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.4 s, sys: 80 ms, total: 31.5 s\n",
      "Wall time: 31.6 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['text'], data['target'], test_size=0.25, random_state=314)\n",
    "\n",
    "model = RuleBased()\n",
    "model.fit(x_train, y_train)\n",
    "sns.heatmap(confusion_matrix(y_true=y_test, y_pred=model.predict(x_test)), \n",
    "            annot=True, annot_kws={\"size\": 10}, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RuleBased + Previous Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier:  86.40%\n",
      "Time execution:\t6min 12.24sec\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase    = True,\n",
    "    tokenizer    = lambda text: Tokenizer(stem='stem', splitter=None, remove_spec=True).tokenize(text), \n",
    "    analyzer     = 'word', \n",
    "    ngram_range  = (1, 3),\n",
    "    max_df       = 0.8,\n",
    "    min_df       = 2, \n",
    "    max_features = 100000,\n",
    ")\n",
    "\n",
    "blending_features = BlendingFeatures([\n",
    "    MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134, loss='hinge'),\n",
    "])\n",
    "        \n",
    "final_classifier = lightgbm.LGBMClassifier(random_state=123142, n_jobs=-1)\n",
    "        \n",
    "model = Pipeline([\n",
    "    ('blending_features', FeatureUnion([('ml_pipeline', Pipeline([('vectorizer', vectorizer), ('classifier', blending_features)])),\n",
    "                  ('rule_based', RuleBased()),  \n",
    "                 ])\n",
    "    ),\n",
    "    ('predictor', final_classifier)\n",
    "])\n",
    "('rule_based', RuleBased())\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(final_classifier)}:  {my_metric(classifier=model)*100:.2f}%')\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a look at the embeddings\n",
    "- 80.30%\n",
    "- 81.30%\n",
    "- 70.40%\n",
    "- 80.90%\n",
    "- 82.15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from os.path import join as path_join\n",
    "from config import APP_DIR\n",
    "\n",
    "vec = KeyedVectors.load_word2vec_format(path_join(APP_DIR, 'wiki-news-300d-1M.vec')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from preprocessing.tokenizer import DictTokenizer, Tokenizer\n",
    "from models import Doc2Vec\n",
    "from models.utils import params_to_numpy\n",
    "from models import get_lgb, LGBMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.785, total=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   28.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................... , score=0.8125, total=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   48.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................... , score=0.8175, total=   7.9s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.825, total=   7.9s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.805, total=   7.9s\n",
      "LGBMClassifier:  80.90%\n",
      "Time execution:\t1min 45.13sec\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "doc2vec = Doc2Vec(vec, tokenizer=DictTokenizer().tokenize)\n",
    "classifier = lightgbm.LGBMClassifier(seed=134, n_jobs=-1)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', doc2vec),\n",
    "    ('predictor', classifier)\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(classifier)}:  {my_metric(classifier=model, verbose=3)*100:.2f}%')\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:32<00:00,  9.95s/it, best loss: -0.8065]\n",
      "Get best lgb:\t1min 39.29sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................... , score=0.7825, total=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.81, total=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   46.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.835, total=  12.8s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.845, total=  16.1s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.835, total=  11.6s\n",
      "LGBMachine:  82.15%\n",
      "Time execution:\t2min 3.13sec\n",
      "------------------------------\n",
      "CPU times: user 9min 29s, sys: 6.87 s, total: 9min 35s\n",
      "Wall time: 3min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "doc2vec = Doc2Vec(vec, tokenizer=DictTokenizer().tokenize)\n",
    "with timeit_context('Get best lgb'):\n",
    "    classifier = get_lgb(x_train=doc2vec.transform(data['text']), y_train=data['target'])\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', doc2vec),\n",
    "    ('predictor', classifier)\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(classifier)}:  {my_metric(classifier=model, verbose=3)*100:.2f}%')\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "- 86.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from preprocessing import FeaturesMaker, Tokenizer\n",
    "from models import BlendingFeatures, RuleBased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.3min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 1.3min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.4min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.3min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.3min\n",
      "LGBMClassifier:  84.55%\n",
      "Time execution:\t6min 35.61sec\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.6min finished\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase    = True,\n",
    "    tokenizer    = lambda text: Tokenizer(stem='stem', splitter=None, remove_spec=True).tokenize(text), \n",
    "    analyzer     = 'word', \n",
    "    ngram_range  = (1, 3),\n",
    "    max_df       = 0.8,\n",
    "    min_df       = 2, \n",
    "    max_features = 100000,\n",
    ")\n",
    "\n",
    "blending_features = BlendingFeatures([\n",
    "    MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134, loss='hinge'),\n",
    "])\n",
    "        \n",
    "final_classifier = lightgbm.LGBMClassifier(random_state=123142, n_jobs=-1)\n",
    "        \n",
    "model = Pipeline([\n",
    "        ('blending_features', FeatureUnion([('ml_pipeline', Pipeline([('vectorizer', vectorizer), ('classifier', blending_features)])),\n",
    "        ('rule_based', RuleBased()), ('feature_engine', FeaturesMaker()) \n",
    "    ])),\n",
    "    ('predictor', final_classifier)\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(final_classifier)}:  {my_metric(classifier=model, verbose=2)*100:.2f}%')\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us create one huge Pipeline that gather all\n",
    "It seems not a good idea but let do an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from models import RuleBased, Doc2Vec, BlendingFeatures\n",
    "from preprocessing import Tokenizer, FeaturesMaker, DictTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from os.path import join as path_join\n",
    "from config import APP_DIR\n",
    "\n",
    "vec = KeyedVectors.load_word2vec_format(path_join(APP_DIR, 'wiki-news-300d-1M.vec')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = CountVectorizer(\n",
    "    lowercase     = True, \n",
    "    tokenizer     = lambda text: Tokenizer(stem='stem', splitter=None, remove_spec=True).tokenize(text), \n",
    "    ngram_range   = (1, 2),\n",
    "    analyzer      = 'word',\n",
    "    max_df        = 1.0,\n",
    "    min_df        = 1,\n",
    "    max_features  = 10000,\n",
    ")\n",
    "\n",
    "char_vectorizer = CountVectorizer(\n",
    "    lowercase     = True, \n",
    "    tokenizer     = None, \n",
    "    ngram_range   = (3, 5),\n",
    "    analyzer      = 'char',\n",
    "    max_df        = 0.95,\n",
    "    min_df        = 10,\n",
    "    max_features  = 1000,\n",
    ")\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    lowercase    = True,\n",
    "    tokenizer    = lambda text: Tokenizer(stem='stem', splitter=None, remove_spec=True).tokenize(text), \n",
    "    analyzer     = 'word', \n",
    "    ngram_range  = (1, 3),\n",
    "    max_df       = 0.8,\n",
    "    min_df       = 2, \n",
    "    max_features = 100000,\n",
    ")\n",
    "\n",
    "doc2vec = Doc2Vec(vec, tokenizer=DictTokenizer().tokenize)\n",
    "\n",
    "word_blending = BlendingFeatures([\n",
    "    MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134, loss='hinge'),\n",
    "])\n",
    "char_blending = BlendingFeatures([\n",
    "    MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134, loss='hinge'),\n",
    "])\n",
    "tfidf_blending = BlendingFeatures([\n",
    "    MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134, loss='hinge'),\n",
    "])\n",
    "emb_classifier = lightgbm.LGBMClassifier(seed=134, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... , score=0.8275, total= 1.9min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... , score=0.8275, total= 2.0min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.9min remaining:    0.0s\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.865, total= 2.0min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.9min remaining:    0.0s\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.835, total= 2.1min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... , score=0.8175, total= 2.0min\n",
      "LGBMClassifier:  83.45%\n",
      "Time execution:\t9min 58.59sec\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.0min finished\n"
     ]
    }
   ],
   "source": [
    "word_pipeline = Pipeline([\n",
    "    ('vectorizer', word_vectorizer),\n",
    "    ('predictor', word_blending)\n",
    "])\n",
    "char_pipeline = Pipeline([\n",
    "    ('vectorizer', char_vectorizer),\n",
    "    ('predictor', char_blending)\n",
    "])\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', tfidf_vectorizer),\n",
    "    ('predictor', tfidf_blending)\n",
    "])\n",
    "emb_pipeline = Pipeline([\n",
    "    ('vectorizer', doc2vec),\n",
    "    ('clasifier', emb_classifier)\n",
    "])\n",
    "        \n",
    "final_classifier = lightgbm.LGBMClassifier(random_state=123142, n_jobs=-1)\n",
    "        \n",
    "model = Pipeline([('features', FeatureUnion([\n",
    "    ('word_pipeline', word_pipeline),\n",
    "    ('char_pipeline', char_pipeline),\n",
    "    ('tfidf_pipeline', tfidf_pipeline),\n",
    "    ('rule_based', RuleBased()),\n",
    "    ('feature_engine', FeaturesMaker()), \n",
    "])),\n",
    "    ('predictor', final_classifier)\n",
    "])\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(final_classifier)}:  {my_metric(classifier=model, verbose=4)*100:.2f}%')\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "Maybe we should pretrain some LightGBM model on bigger dataset and use continuous learning in the cross val metric? (big_data was formed in Analyze.ipynb module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data = pd.read_parquet(path_join(DATA_DIR, 'big_data.parquet'))\n",
    "big_data_x = big_data.text\n",
    "big_data_y = big_data.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['text'], data['target'], test_size=0.25, random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# doc2vec = Doc2Vec(\n",
    "#     word2vec=vec, \n",
    "#     tokenizer = Tokenizer(stem='lem', remove_spec=True).tokenize,\n",
    "# )\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    lowercase    = True,\n",
    "    tokenizer    = lambda text: Tokenizer(stem='stem', splitter=None, remove_spec=True).tokenize(text), \n",
    "    analyzer     = 'word', \n",
    "    ngram_range  = (1, 3),\n",
    "    max_df       = 0.8,\n",
    "    min_df       = 2, \n",
    "    max_features = 100000,\n",
    ")\n",
    "classifier = LogisticRegression(random_state=1324, n_jobs=-1)\n",
    "lgb = lightgbm.LGBMClassifier(seed=124, n_jobs=-1)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', tfidf_vectorizer),\n",
    "    ('classifier', classifier),\n",
    "])\n",
    "\n",
    "# lgb_model = Pipeline([\n",
    "#     ('vectorizer', doc2vec),\n",
    "#     ('classifier', lgb),\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "Let compare different x_train variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.00%\n",
      "CPU times: user 4.99 s, sys: 12 µs, total: 4.99 s\n",
      "Wall time: 5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with timeit_context('Fitting time'):\n",
    "    model.fit(big_data_x, big_data_y)\n",
    "\n",
    "with timeit_context('Pred time'):\n",
    "    preds = model.predict(x_test)\n",
    "    print(f'Accuracy: {accuracy_score(y_true=y_test, y_pred=preds)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time:\t20.12sec\n",
      "Accuracy: 84.40%\n",
      "Pred time:\t5.53sec\n",
      "CPU times: user 25.7 s, sys: 112 ms, total: 25.8 s\n",
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with timeit_context('Fitting time'):\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "with timeit_context('Pred time'):\n",
    "    preds = model.predict(x_test)\n",
    "    print(f'Accuracy: {accuracy_score(y_true=y_test, y_pred=preds)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time:\t4min 40.44sec\n",
      "Accuracy: 89.60%\n",
      "Pred time:\t5.30sec\n",
      "CPU times: user 4min 43s, sys: 3.2 s, total: 4min 46s\n",
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with timeit_context('Fitting time'):\n",
    "    model.fit(list(big_data_x.values) + list(x_train.values), list(big_data_y.values) + list(y_train.values))\n",
    "\n",
    "with timeit_context('Pred time'):\n",
    "    preds = model.predict(x_test)\n",
    "    print(f'Accuracy: {accuracy_score(y_true=y_test, y_pred=preds)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "Let compare different x_train variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time:\t12.92sec\n",
      "Accuracy: 83.60%\n",
      "Pred time:\t2.88sec\n",
      "CPU times: user 27 s, sys: 292 ms, total: 27.3 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with timeit_context('Fitting time'):\n",
    "    lgb_model.fit(x_train.values, y_train.values)\n",
    "\n",
    "with timeit_context('Pred time'):\n",
    "    preds = lgb_model.predict(x_test)\n",
    "    print(f'Accuracy: {accuracy_score(y_true=y_test, y_pred=preds)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time:\t1min 12.73sec\n",
      "Accuracy: 82.00%\n",
      "Pred time:\t2.10sec\n"
     ]
    }
   ],
   "source": [
    "with timeit_context('Fitting time'):\n",
    "    lgb_model.fit(big_data_x, big_data_y)\n",
    "\n",
    "with timeit_context('Pred time'):\n",
    "    preds = lgb_model.predict(x_test)\n",
    "    print(f'Accuracy: {accuracy_score(y_true=y_test, y_pred=preds)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time:\t1min 18.62sec\n",
      "Accuracy: 81.40%\n",
      "Pred time:\t2.11sec\n",
      "CPU times: user 1min 49s, sys: 250 ms, total: 1min 50s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with timeit_context('Fitting time'):\n",
    "    lgb_model.fit(list(big_data_x.values) + list(x_train.values), list(big_data_y.values) + list(y_train.values))\n",
    "\n",
    "with timeit_context('Pred time'):\n",
    "    preds = lgb_model.predict(x_test)\n",
    "    print(f'Accuracy: {accuracy_score(y_true=y_test, y_pred=preds)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7fef896c1cf8>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.get_params()['steps'][1][1].booster_.save_model('light.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "Let compare different x_train variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from models import BlendingFeatures\n",
    "from preprocessing import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase    = True,\n",
    "    tokenizer    = lambda text: Tokenizer(stem='stem', splitter=None, remove_spec=True).tokenize(text), \n",
    "    analyzer     = 'word', \n",
    "    ngram_range  = (1, 3),\n",
    "    max_df       = 0.8,\n",
    "    min_df       = 2, \n",
    "    max_features = 100000,\n",
    ")\n",
    "\n",
    "blending_features = BlendingFeatures([\n",
    "    MultinomialNB(), LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134, loss='hinge'),\n",
    "])\n",
    "        \n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', blending_features),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [10:22<00:00, 208.59s/it]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(random_state=1324, n_splits=3, shuffle=True)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "log = LogisticRegression(random_state=123142)\n",
    "lin = LinearSVC(random_state=124)\n",
    "sgd = SGDClassifier(random_state=134)\n",
    "    \n",
    "meta_features = np.array([None] * big_data_x.shape[0])\n",
    "for train_index, test_index in tqdm(kfold.split(big_data_x), total=3):\n",
    "    train_data = vectorizer.fit_transform(big_data_x.iloc[train_index])\n",
    "    test_data  = vectorizer.transform(big_data_x.iloc[test_index])\n",
    "    mnb.fit(train_data, big_data_y.iloc[train_index])\n",
    "    lin.fit(train_data, big_data_y.iloc[train_index])\n",
    "    log.fit(train_data, big_data_y.iloc[train_index])\n",
    "    sgd.fit(train_data, big_data_y.iloc[train_index])\n",
    "    meta_features[test_index] = list(zip(\n",
    "        mnb.predict_proba(test_data)[:, 1], \n",
    "        log.predict_proba(test_data)[:, 1],\n",
    "        lin.predict(test_data),\n",
    "        sgd.predict(test_data),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = np.array([np.array(i) for i in meta_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import get_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:33<00:00,  1.56s/it, best loss: -0.89748]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f3c842db2b0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lgb = lightgbm.LGBMClassifier(seed=124, n_jobs=-1).fit(meta, big_data_y.values)\n",
    "lgb = get_lgb(meta, big_data_y.values)\n",
    "# lgb_model.get_params()['steps'][1][1].booster_.save_model('light.txt.init')\n",
    "lgb.model.booster_.save_model('light.txt.init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.75, boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=1.0, feature_fraction=0.8,\n",
       "        importance_type='split', learning_rate=0.061500000000000006,\n",
       "        max_depth=3, max_drop=33, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_data_in_leaf=62, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_iterations=151, num_leaves=77,\n",
       "        objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "        subsample_freq=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "### Let's try transfer learning with lgb\n",
    "- 76.7%\n",
    "- 85.55%\n",
    "- 86.05%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f6ed9a21d416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m lgb_model1 = Pipeline([\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'vectorizer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc2vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlight_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc2vec' is not defined"
     ]
    }
   ],
   "source": [
    "class Light(object):\n",
    "    def __init__(self, model_path, threshold: float = 0.5):\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model = lightgbm.train(params={}, train_set=lightgbm.Dataset(x_train, y_train), init_model=self.model_path)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        return [i > self.threshold for i in self.model.predict(x_test)]\n",
    "    \n",
    "    \n",
    "light_model = Light(model_path='light.txt.init')\n",
    "\n",
    "lgb_model1 = Pipeline([\n",
    "    ('vectorizer', doc2vec),\n",
    "    ('classifier', light_model),\n",
    "])\n",
    "\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(final_classifier)}:  {my_metric(classifier=lgb_model1, verbose=4)*100:.2f}%')\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.blending import BlendingFeatures\n",
    "\n",
    "blending_features = BlendingFeatures([\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=123142), LinearSVC(random_state=124), SGDClassifier(random_state=134, loss='hinge'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.061500000000000006,\n",
       " 'max_depth': 3,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 77,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0,\n",
       " 'bagging_fraction': 0.75,\n",
       " 'feature_fraction': 0.8,\n",
       " 'max_drop': 33,\n",
       " 'min_data_in_leaf': 62,\n",
       " 'num_iterations': 151}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... , score=0.8725, total=  24.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   48.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.845, total=  23.6s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... , score=0.8875, total=  23.6s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.855, total=  23.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n",
      "WARNING:root:'LinearSVC' object has no attribute 'predict_proba'\n",
      "WARNING:root:probability estimates are not available for loss='hinge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... , score=0.8425, total=  23.5s\n",
      "Light:  86.05%\n",
      "Time execution:\t1min 59.36sec\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "class Light(object):\n",
    "    def __init__(self, model_path, threshold: float = 0.5):\n",
    "        self.model_path = model_path\n",
    "        self.model      = None\n",
    "        self.threshold  = threshold\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model = lightgbm.train(params={'seed': 123, 'n_jobs': -1}, train_set=lightgbm.Dataset(x_train, y_train), init_model=self.model_path)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        return [i > self.threshold for i in self.model.predict(x_test)]\n",
    "\n",
    "light = Light(model_path='light.txt.init')\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('blending', blending_features),\n",
    "    ('final_classfier', light)\n",
    "])\n",
    "\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(light)}:  {my_metric(classifier=model, verbose=4)*100:.2f}%')\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VedarModel\n",
    "- 50.00%\n",
    "- 62.50%\n",
    "- 61.95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.8min remaining:  4.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vedar:  61.95%\n",
      "Time execution:\t3min 55.92sec\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class Vedar(BaseEstimator):\n",
    "    def __init__(self, eval_metric = accuracy_score):\n",
    "        self.analyser = SentimentIntensityAnalyzer()\n",
    "        self.threshold = 0.0\n",
    "        self.eval_metric = eval_metric\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        predictions = [self.analyser.polarity_scores(sample) for sample in x_train]\n",
    "        predictions = np.array([pred['pos'] + pred['neu'] * 0.5 for pred in predictions])\n",
    "        eval_metrics = []\n",
    "        thrs         = []\n",
    "        for thr in np.arange(0.05, 0.9, 0.05):\n",
    "            eval_metrics.append(self.eval_metric(predictions > thr, y_train))\n",
    "            thrs.append(thr)\n",
    "        self.threshold = thrs[np.argmax(eval_metrics)]\n",
    "        \n",
    "        # return (pos - neg) / (max([pos, neg]))\n",
    "        # return pos / (pos + neg)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        predictions = [self.analyser.polarity_scores(sample) for sample in x_test]\n",
    "        print(predictions)\n",
    "        return np.array([pred['pos'] + pred['neu'] * 0.5 > self.threshold for pred in predictions])\n",
    "    \n",
    "vedar = Vedar()\n",
    "\n",
    "with timeit_context('Time execution'):\n",
    "    print(f'{model_name(vedar)}:  {my_metric(classifier=vedar, verbose=4, n_jobs=-1)*100:.2f}%')\n",
    "print('-' * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 ucu",
   "language": "python",
   "name": "ucu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
