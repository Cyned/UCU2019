{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of 5.Advanced.ipynb","version":"0.3.2","provenance":[{"file_id":"1yFqWh9LIQxYgjgqKEWJCOqZUL6wwA_Of","timestamp":1563968842941}],"collapsed_sections":["WrN-j9kLdo0j","2q_ybKAFG30i","h8sTvEYjG0lU","zB9kVYsbTigs","k2uN8ns6dthy","zdELt4o1OgPC","Tv2KiWJjPiGu","qIIKlZjLPf1z","lWgzXa6PUu8O","kMKmanlnPsBq","-r6Hr_ZmOnwS","IlSuwnpbNcvy","LmYuseLfVok2","XBtVbtE0VhI6","x38Ssx8AhPjV","jPS7h6Daguv9","JazUz2LjcO5Z","Ed4lSkdEH9JR","Vh_TisuOcOxA","4wsMmYiud6MG","fmitJ6K9vlCU","6FIuf47ud4oQ"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WrN-j9kLdo0j","colab_type":"text"},"source":["# Knowledge Graphs and Its Associates\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"2q_ybKAFG30i","colab_type":"text"},"source":["## Entities"]},{"cell_type":"markdown","metadata":{"id":"NTa4BNPwacva","colab_type":"text"},"source":["* **[Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)** - is typically a problem of detection entities of type LOCation, ORGanization, or PERson.\n","<br>Note: each of those entities might span several words/tokens in a given text.\n","<br>Typically, NER is solved as follows: linguistic grammar-based, statistical models or machine learning.\n","<br>Conditional Random Fields are used for the tasks.\n","<br>\n","Examples:\n","  * Kaggle competition [dataset](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus).\n","  * [DataTurk](https://dataturks.com/projects/Mohan/Best%20Buy%20E-commerce%20NER%20dataset) - search queries with entities.\n","  * [Stanford NER](https://nlp.stanford.edu/software/CRF-NER.shtml)\n","  * [Spacy](https://en.wikipedia.org/wiki/SpaCy)\n","  * Apache [OpenNLP](http://opennlp.apache.org/index.html)\n","\n","* **[Coreference resolution](https://en.wikipedia.org/wiki/Coreference#Coreference_resolution)**\n","<br>\n","Another important problem with regards to the entities - is conreference resolution.\n","<br>Coreference denotes a presence of several expressions in a text that refer to the same person/thing.\n","<br>\n","For example:\n","<br>\n","> **The food** was salty so guests did not enjoy **it**.\n","<br>\n","> **The student** was absent for 3 month. **Such person** won't pass any exam.\n","\n","* **[Entity linking](https://en.wikipedia.org/wiki/Entity_linking) or Disambiguation**\n","<br>\n","Entity disambiguation is a problem of matching the identity of the entity mentioned in the text to actual entity.\n","<br>Typically, supervised learning is used to solve this problem where anchor texts are leveraged in the training data.\n","<br>Further, several explorations were made with [clean unambiguous training data](http://www.aclweb.org/anthology/C10-1145), or with [topically related texts that potentially have similar types](https://www.cc.gatech.edu/~zha/CSE8801/query-annotation/p457-kulkarni.pdf)\n","<br>of entities in them, etc.\n","<br>\n","For example:\n","<br>\n","> Donald **Trump** and **Trump** card.\n","<br>\n",">**Paris** Hilton and **Paris** city."]},{"cell_type":"markdown","metadata":{"id":"h8sTvEYjG0lU","colab_type":"text"},"source":["## Relations"]},{"cell_type":"markdown","metadata":{"id":"1URgJ-tpbnE7","colab_type":"text"},"source":["Entities could have several various relationships between each other that are important to extract. For example:\n","\n","* Types of relationships:\n","\n","  * *is-a* - the relationship between two entities in which one entity inherits from the other\n","\n","  * *Hypernyms* - a word with a broad meaning constituting a category into which words with more specific meanings fall;\n","  \n","  * *Hyponyms* - is a word or phrase whose semantic field[1] is included within that of another word.\n","  <br>Hyponyms denotes a subset of the hypernym.\n","  \n","  * *Meronymy* denotes a constituent part of, or a member of something. Meronym is a part of a whole!\n","\n","  * *Synsets* - A set of one or more synonyms that are interchangeable in some context without changing the truth value of the\n","  <br>proposition in which they are embedded;\n","\n","  * *Metonymy* - the substitution of the name of an attribute or adjunct for that of the thing meant, for example suit for business executive.\n","  \n","  * *Anything*: who is married on who, what causes what, etc.\n","  \n","* Relation extraction\n","\n","  * Methodologies: [Regex](http://www.aclweb.org/anthology/D08-1003), [Rule based](http://iswc2012.semanticweb.org/sites/default/files/76490257.pdf), [Wikipedia categories](http://pages.cs.wisc.edu/~anhai/papers/kcs-sigmod13.pdf), [Distant supervision](https://web.stanford.edu/~jurafsky/mintz.pdf), [Bayesian networks](http://aclweb.org/anthology/D17-1192), [Factor graphs](https://cs.stanford.edu/people/czhang/zhang.thesis.pdf)."]},{"cell_type":"markdown","metadata":{"id":"zB9kVYsbTigs","colab_type":"text"},"source":["### Knowledge Bases/Knowledge Graphs"]},{"cell_type":"markdown","metadata":{"id":"vvXusNGhTnl8","colab_type":"text"},"source":["* [WordNet](https://en.wikipedia.org/wiki/WordNet)\n","<br>\n","WordNet is a lexical database for English. It groups English words into synonyms (synsets), provides their short\n","<br>\n","descriptions and usages. Moreover, it contains several relations between the enties of synsets.\n","\n","* [OmegaWiki](http://www.omegawiki.org/Meta:Main_Page), [BabelNet](https://babelnet.org/)\n","<br>\n","OmegaWiki aims at creating dictionaries of all words of all languages. BabelNet is a multilingual encyclopedic dictionary.\n","\n","* <a href=\"https://en.wikipedia.org/wiki/Taxonomy_(general)\">**Taxonomy**</a>\n","<br>\n","Taxonomy refers to the hierarchical categorization where relatively well-defined classes are nested under broader categories.\n","\n","* [Folksonomy](https://en.wikipedia.org/wiki/Folksonomy)\n","<br>\n","Folksonomy is a relatively new system where users apply tags to online items.\n","<br>\n","As opposed to Taxonomy, Folksonomy does not derive a hierarchical structure betwen the tags but rather only assigns them.\n","\n","* <a href=\"https://en.wikipedia.org/wiki/Ontology_(information_science)\">**Ontology**</a>\n","<br>\n","Ontology is a representation, naming, definitions, categories, properties, relations of the concepts/entities\n","<br>\n","for several or all domains.\n","\n","* [DBPedia](https://en.wikipedia.org/wiki/DBpedia)\n","<br>\n","DBPedia aims at extracting structured content from the Wikipedia. It describes about 4.5M entiuties,\n","<br>\n","with about 1.5M persons, 700K places, 240K organizations, etc.\n","\n","* <a href=\"https://en.wikipedia.org/wiki/YAGO_(database)\">YAGO</a>\n","<br>\n","YAGO is an open sourced knowlege base that was developed in Max Planck Institute.\n","<br>\n","This knowledge base contains over 10M entities and about 120M facts about those entities.\n","<br>\n","YAGO extracts information from Wikipedia boxes, WordNet and [GeoNames](https://en.wikipedia.org/wiki/GeoNames).\n","\n","* [**Knowledge Bases**](https://en.wikipedia.org/wiki/Knowledge_base) and [Knowledge Graphs](https://en.wikipedia.org/wiki/Knowledge_Graph)\n","<br>\n","KB or KG are technology to store complex structured and unstructured information.\n","<br>\n","One of the main example of the Knowledge Graph is [Google Knowledge Graph](https://en.wikipedia.org/wiki/Knowledge_Graph) that was in part\n","<br>\n","powered by [Freebase](https://en.wikipedia.org/wiki/Freebase) (Freebase is a large collaborative knowledge base that contain the\n","<br>\n","data composed mainly by its community members.).\n","<br>\n","Another example: Knowledge Graphs with [DeepDive](https://meta.wikimedia.org/wiki/Research:Wikipedia_Knowledge_Graph_with_DeepDive).\n","\n","* <a href=\"https://en.wikipedia.org/wiki/Commonsense_knowledge_(artificial_intelligence)\">Commonsense knowledge</a>\n","<br>\n","Common sense knowledge consists of facts about everyday life, e.g., The sky is blue, a lemon is yellow and sour.\n","<br>\n","A large corpus of this data called [Open Mind Common Sense](https://en.wikipedia.org/wiki/Open_Mind_Common_Sense) (OMCS) was created by MIT."]},{"cell_type":"markdown","metadata":{"id":"k2uN8ns6dthy","colab_type":"text"},"source":["# Sequence Models\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"z-6iHb4HJKe3","colab_type":"text"},"source":["Sequential modeling could be either conditioned on sequential data or require to generate sequential data.\n","\n","Example 1: read a news paper article and pridict the gender of the writer; read the movie review and predict the sentiment.\n","\n","Example 2: POS tagging, machine translation, summarization, generation, image generation, text to speech, etc."]},{"cell_type":"markdown","metadata":{"id":"zdELt4o1OgPC","colab_type":"text"},"source":["## HMMs and CRFs"]},{"cell_type":"markdown","metadata":{"id":"Tv2KiWJjPiGu","colab_type":"text"},"source":["\n","### HMM"]},{"cell_type":"markdown","metadata":{"id":"l_k29GTH2q--","colab_type":"text"},"source":["* **Hidden Markov Model (HMM)**\n","<br>\n","Is a statistical Markov model in which we assume that the process that is being modeled is Markov process\n","<br>(probability of the event depends only on the previous state/event) with unobserved states."]},{"cell_type":"markdown","metadata":{"id":"zaVIPcGGiWfP","colab_type":"text"},"source":["<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/HiddenMarkovModel.svg/750px-HiddenMarkovModel.svg.png width=50%>\n","\n","> (c) [Wikipedia](https://en.wikipedia.org/wiki/Hidden_Markov_model)"]},{"cell_type":"markdown","metadata":{"id":"dkQf_Y7-ff0a","colab_type":"text"},"source":["> So in the *Markov process* the states are directly observed, thus, we have only state transition probabilities.\n","<br>In the *[Hidden Markov Model](http://cs229.stanford.edu/section/cs229-hmm.pdf)* the state is not directly visible, but the output\n","<br>(dependent on the state) is visible. Thus, each state has a probability distribution over the possible output tokens.\n","<br>\n","HMM are well known and used for the following applications: part of speech tagging, reinforcement learning and temporal pattern recognition\n","<br>(speech, handwriting, gestures, etc.), bioinformatics, etc.\n","<br><br>\n","HMM can be seen as a generalization of a mixture model where the hidden variables are related through\n","<br>a Markov process rather than independent (as we have seen in the Topic Modeling).\n","<br><br>\n","For example, consider part-of-speech tagging problem, where POS are the hidden states that have some observed word representation.\n","<br>As a result, we need the entire sequence of the states to be computed - [Viterbi algorithm](https://en.wikipedia.org/wiki/Viterbi_algorithm)\n","<br>(dynamic programming + backtracking) can be used."]},{"cell_type":"markdown","metadata":{"id":"a3YtyRccfIxX","colab_type":"text"},"source":["<img src=\"http://cse24-iiith.virtual-labs.ac.in/exp7/Exp5/viterbi-4.gif\" width=50%>\n","\n","> (c) [NLP Lab of IIIT-H](http://cse24-iiith.virtual-labs.ac.in/exp7/index.html)"]},{"cell_type":"markdown","metadata":{"id":"qIIKlZjLPf1z","colab_type":"text"},"source":["### CRF"]},{"cell_type":"markdown","metadata":{"id":"nkNyEA8N9B8y","colab_type":"text"},"source":["* ** [Conditional Random Fields](https://www.research.ed.ac.uk/portal/files/10482724/crftut_fnt.pdf) (CRF)**\n","<br>\n","Is also a statistical modeling method that is usually applied for structured prediction (predict the sequence of labels; parsing; named entity recognition,\n","<br>shallow parsing, etc.). [CRF](https://en.wikipedia.org/wiki/Conditional_random_field) is a discriminative undirected probabilistic graphical models\n","<br>which somehow encodes known relationships between observations and construct consistent interpretations.\n","<br>CRF is defined on top of observations X and random variables Y.\n","<br>In particular, in conditional random field (X, Y) - random variable Y that is conditioned on X follows Markov property (memoryless).\n","<br>\n","In the context of CRFs, we are defining feature functions that takes as input:\n","<br>(1) sentence, (2) position of the word, (3) label of the i-th word, (4) label of the previous word - and outputs a real value (feature value).\n","<br>We can convert those features and feature scores to the probabilities by using exponentiation and normalization.\n","<br>Label sequence modeled as a normalized product of feature functions.\n","<br>\n","In order to express probability $P(y | x, w)$ of the sequence through the feature functions, exponentiation is used.\n","$$ P (y | x, w) = \\frac{ \\sum_{i=1}^{n} \\sum_{j} w_j f_j(y_{i-1}, y_i, x, i ) }{\\sum_{y \\in Y} \\sum_{i=1}^{n} \\sum_{j} w_j f_j(y_{i-1}, y_i, x, i )} $$\n","<br>\n","To learn the weights of the features, we need to compute the gradient of the log probability p(labels | sentence).\n","<br>More intuitive explanation in this [post](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/).\n","<br><br>\n","Two options are possible once it comes to the inference over CRFs, either the graph is a chain or tree - then we can use HMM algorithms,\n","<br>or if the graph contains loops - we can use some approximations (e.g. [Loopy belief propagation](https://en.wikipedia.org/wiki/Belief_propagation#Approximate_algorithm_for_general_graphs)).\n","<br><br>\n","You can play with a [CRF based NER](http://nlp.stanford.edu:8080/ner/) system provided in a [demo](https://nlp.stanford.edu/software/CRF-NER.shtml) by Stanford."]},{"cell_type":"markdown","metadata":{"id":"itV3nnHkmZMX","colab_type":"text"},"source":["<img src=\"https://www.codeproject.com/KB/recipes/559535/gerative-discriminative.png\" width=60%>"]},{"cell_type":"markdown","metadata":{"id":"rPrkzu9tkPQT","colab_type":"text"},"source":["> Moreover, CRF could be used beyond sequences, but also in the form of trees, and thus enabling computation of the constituency parsing\n","<br>(one that is described in the preprocessing section)."]},{"cell_type":"markdown","metadata":{"id":"UxtvbMJ8WD_G","colab_type":"text"},"source":["More information on structured predictors [here](http://lxmls.it.pt/2018/strlearn.pdf)."]},{"cell_type":"markdown","metadata":{"id":"xy143ivFdyDe","colab_type":"text"},"source":["# Deep Learning\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"fxiIxPryUpfi","colab_type":"text"},"source":["For the sake of completeness, we should also consider Reccurent Neural Networds (RNN) that are used to handle textual inputs as sequences.\n","\n","When we talk about Deep Learning, what we actually mean - is deep (many many layers) neural network training and inference."]},{"cell_type":"markdown","metadata":{"id":"lWgzXa6PUu8O","colab_type":"text"},"source":["## **Reccurent Neural Networks (RNN)** for sequence modeling"]},{"cell_type":"markdown","metadata":{"id":"-_2apyLukZYj","colab_type":"text"},"source":["You can read up more on the attention models in the very intuitive explanations from Chris Dyer from\n","<br>DeepMind and his [presentation](http://lxmls.it.pt/2018/lxmls-dl3.pdf) at LxMLs 2018 in Lisbon."]},{"cell_type":"markdown","metadata":{"id":"kMKmanlnPsBq","colab_type":"text"},"source":["### Language modeling"]},{"cell_type":"markdown","metadata":{"id":"ITEeA6KiPtuH","colab_type":"text"},"source":["Language models assings probabilities to the sequences of the words. Typically a chain rule is used.\n","\n","$ p(w_1, \\dots, w_l)  = p(w_1) \\times p(w_2 | w_1) \\times p(w_3 | w_1, w_2) \\times \\dots $\n","\n","Basically we need to represent an arbitrary lond history. \n","\n","For this, we could train a neural network that builds a representation of sequences of unbound length.\n","\n","$\\hat y = Wx + b$  - linear regression where we need to minimize the prediction error on the given dataset.\n","\n","If we assume $h = g(Vx + c)$, $\\hat y = Wh + b$ - non-linear regression.\n","\n","$h$ - is kind of induced features in a linear classifier."]},{"cell_type":"markdown","metadata":{"id":"-r6Hr_ZmOnwS","colab_type":"text"},"source":["### RNN"]},{"cell_type":"markdown","metadata":{"id":"5g9FSYBPSVWe","colab_type":"text"},"source":["A typical Feed-forward Neural network would have the structure as follows (just as described above in fact):\n","\n","$h = g(Vx + c)$ \n","\n","$\\hat y = Wh + b$\n","\n","On the contrary Recurrent Neural Network:\n","\n","$h_t = g(Vx_t + Uh_{t-1} + c)$\n","\n","$\\hat y_t = Wh_t + b$"]},{"cell_type":"markdown","metadata":{"id":"RWTcKesKbvFn","colab_type":"text"},"source":["In a nutshell, [RNN](http://www.deeplearningbook.org/contents/rnn.html) accepts an input vector $X$ and produces an output vector $Y$.\n","<br>What is interesting here is that the output is produced not only by the provided $X$, but also by the whole history the model was fed with.\n","<br>After each iteration (each input), RNN updates a hidden state (vector) $h$, which for example could be a combination of the two:\n","<br>weighed sum of the input and weighted sum of the hidden state.\n","<br>To go even deeper, we could define two networks, one that accepts normal input (encoder) as described earlier,\n","<br>and the other that accepts the output of the first network as an input (decoder)."]},{"cell_type":"markdown","metadata":{"id":"9fiVQ0s_b8dy","colab_type":"text"},"source":["[Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) shows several options of the RNN applied to the text\n","<br>(if interested you could check Andrej's [vanilla char-level language RNN](https://gist.github.com/karpathy/d4dee566867f8291f086) implementation).\n","\n","<img src=\"http://karpathy.github.io/assets/rnn/diags.jpeg\" wirth=60%>\n","<br>\n","`Each rectangle is a vector and arrows represent functions (e.g. matrix multiply). Input vectors are in red, output vectors are in blue and green vectors hold the RNN's state (more on this soon). From left to right: (1) Vanilla mode of processing without RNN, from fixed-sized input to fixed-sized output (e.g. image classification). (2) Sequence output (e.g. image captioning takes an image and outputs a sentence of words). (3) Sequence input (e.g. sentiment analysis where a given sentence is classified as expressing positive or negative sentiment). (4) Sequence input and sequence output (e.g. Machine Translation: an RNN reads a sentence in English and then outputs a sentence in French). (5) Synced sequence input and output (e.g. video classification where we wish to label each frame of the video). Notice that in every case are no pre-specified constraints on the lengths sequences because the recurrent transformation (green) is fixed and can be applied as many times as we like.`"]},{"cell_type":"markdown","metadata":{"id":"IlSuwnpbNcvy","colab_type":"text"},"source":["#### How do we train RNN?\n"]},{"cell_type":"markdown","metadata":{"id":"bjlSbim_NfPN","colab_type":"text"},"source":["Let's consider **many-to-many** example. For each of the many outputs we actually know what would be the idea outcome (e.g., next word prediction in a sentence) and each of those output, thus, produced a error/cost. We could formulate a total cost/loss as a sum of the outcomes cotsts $F$. \n","Similarly, parmeters are updated based on the propagated errors from each of the outputs.\n"]},{"cell_type":"markdown","metadata":{"id":"vLqB7XqkRVTr","colab_type":"text"},"source":["<img src=\"https://docs.google.com/drawings/d/e/2PACX-1vQKS_hnAXySuEFOXK3ME8UW96uD0iFN_ggMA_WrPvduLAIDIloL6ow1ttDDkVXiQg-ydYFTHn-az4P6/pub?w=689&h=575\">\n","\n","$\\frac{dF}{dU} = \\sum_{t=1}^{4} \\frac{dF}{dh_{t}} \\frac{fh_{t}}{dU}$"]},{"cell_type":"markdown","metadata":{"id":"LmYuseLfVok2","colab_type":"text"},"source":["#### Read and summarize"]},{"cell_type":"markdown","metadata":{"id":"S0q-JF8aSyO4","colab_type":"text"},"source":["Let's consider another example: many-to-one, or \"read and summarize\" a sequence into a single vector."]},{"cell_type":"markdown","metadata":{"id":"fenbBt9JTI9W","colab_type":"text"},"source":["<img src=\"https://docs.google.com/drawings/d/e/2PACX-1vQgGXBEeO9TQ_F_ouOasobFJaMR__iQobAZJYL4H4_Ay4En_5mMMt68CjZ8Xs6ODSYe8O6qT3u81dpW/pub?w=473&h=562\" width=45%>\n","<img src=\"https://docs.google.com/drawings/d/e/2PACX-1vTfE3Zh6IRjvuxe8YDsR_dcN09QD7yr5R-mq_vB7-57PahL_o8Z7PCWZhVg4lmNknquJvxEJJ1RLJHF/pub?w=454&h=648\" width=45%>"]},{"cell_type":"markdown","metadata":{"id":"_NLz6RjQUNsI","colab_type":"text"},"source":["$h_t = g(Vx_t + Uh_{t-1} + c)$\n","\n","$\\hat h = max(h_t)$\n","\n","$\\hat y_t = W \\hat h_t + b$"]},{"cell_type":"markdown","metadata":{"id":"XBtVbtE0VhI6","colab_type":"text"},"source":["#### How do we actually select the output $y'$?"]},{"cell_type":"markdown","metadata":{"id":"4kGIzwNZVsyg","colab_type":"text"},"source":["<img src=\"https://docs.google.com/drawings/d/e/2PACX-1vQSfbYA8T5ULcgfwDSi3k6jDbz-z11nkon45gsrc2jxyKWBUyEkmIVpwnrQAJymIWIag6nENAKwRsAQ/pub?w=473&h=315\">"]},{"cell_type":"markdown","metadata":{"id":"--GeUQ8KW-hE","colab_type":"text"},"source":["Where in in fact $y'$ is first a vector of the size of the vocabulary. Firther we apply softmax and, thus, estimate something like $P(W|w_1, w_2, w_3, w_4)$. In $y'$ each dimention correspond to a word in a closed vocabulary V. And aprobability of each word is estimated as follows:\n","\n","$u = Wh + b$\n","\n","$p_i = \\frac{\\exp{u_i}}{\\sum_j \\exp{u_j}}$"]},{"cell_type":"markdown","metadata":{"id":"x38Ssx8AhPjV","colab_type":"text"},"source":["### LSTM"]},{"cell_type":"markdown","metadata":{"id":"RXVcsVCxhRUW","colab_type":"text"},"source":["LSTM ([Colah's blog intuitive explanations](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)) is conceptually similar to the RNN explained above,\n","<br>though it adds to each of the reccurent unit a memory notion, thus, each recurrent unit becomes slightly more complicated."]},{"cell_type":"markdown","metadata":{"id":"Rm9yHW2UaLUU","colab_type":"text"},"source":["$c_t = c_{t-1} + f(x_t)$, where $f(x_t) = tanh(Wx_t + b)$.\n","\n","$h_t = g(c_t)$"]},{"cell_type":"markdown","metadata":{"id":"UhyPoF7jc9M7","colab_type":"text"},"source":["<img  src=\"https://docs.google.com/drawings/d/e/2PACX-1vTr8daJ-L_O4s3iQD5MeNIWqDxACz4fFdfNVUBDhpnWZ86VMcgLm67UTo9zou57d18pMqtDkL99cLq6/pub?w=450&h=553\">"]},{"cell_type":"markdown","metadata":{"id":"Le4tfpZvddus","colab_type":"text"},"source":["Note $\\frac{dc_t}{dc_{t-1}} \\sim I$\n","\n","So to summarize the image:\n","\n","$c_t = f_t \\cdot c_{t-1} + i_t \\cdot f([x_t;h_{t-1}]) $\n","\n","$h_t = g(c_t)$\n","\n","$f_t = \\sigma(f_f([x_t;h_{t-1}]))$  - forget gate\n","\n","$i_t = \\sigma(f_i([x_t;h_{t-1}]))$  - input gate"]},{"cell_type":"markdown","metadata":{"id":"KpTu4EaOdmB6","colab_type":"text"},"source":["To make everything above an actual LSTM - we also add the output gate: \n","$o_t = \\sigma(f_o([x_t;h_{t-1}]))$  - output gate\n","\n","And thus,  $h_t = o_t \\cdot g(c_t)$"]},{"cell_type":"markdown","metadata":{"id":"ZpAAtozBfPY1","colab_type":"text"},"source":["Moreover, we can tune the balance between input and forget gate by allowing $f_t   = 1 - i_t$."]},{"cell_type":"markdown","metadata":{"id":"ku-dUw8paJ6j","colab_type":"text"},"source":["Nice LSTM illustration published by [Shi Yun on Medium](https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714).\n","<br>\n","<img src=\"https://cdn-images-1.medium.com/max/1600/1*S0Y1A3KXYO7_eSug_KsK-Q.png\" width=80%>\n","\n","Check out more closely each separate unit.\n","<br>\n","<img src=https://cdn-images-1.medium.com/max/1600/1*laH0_xXEkFE0lKJu54gkFQ.png width=70%>"]},{"cell_type":"markdown","metadata":{"id":"jPS7h6Daguv9","colab_type":"text"},"source":["### Conditional Language Models"]},{"cell_type":"markdown","metadata":{"id":"nP7OUBX1g24G","colab_type":"text"},"source":["Similar to the previously discussed ones, but here we will be modeling $P(W | w_1, \\dots w_k, X)$ - probability of a sequence of words\n","<br>given some conditioning context $X$."]},{"cell_type":"markdown","metadata":{"id":"Xa8xryYJhKcQ","colab_type":"text"},"source":["Examples:\n","\n","* A sentence in english $\\rightarrow$ a sentence in chinese.\n","* A sentence in english $\\rightarrow$ a sentence in french.\n","* A document $\\rightarrow$ it's summary.\n","* Speech $\\rightarrow$ text.\n","* Question and a document $\\rightarrow$ answer.\n","* Question and image $\\rightarrow$ answer.\n","* An image $\\rightarrow$ its textual description.\n","* Meteo mesures $\\rightarrow$ weather report.\n","* Topic $\\rightarrow$ a document on this topic."]},{"cell_type":"markdown","metadata":{"id":"aCk1TFuJkNjg","colab_type":"text"},"source":["#### Encoder-Decoder models"]},{"cell_type":"markdown","metadata":{"id":"arqMdzmSltDy","colab_type":"text"},"source":["<img src=\"https://docs.google.com/drawings/d/e/2PACX-1vQva9Ns8Ip_837SQr-yM4IJykLcjy3cmxdJxan1iRConAs0n0BkNw1xG10iXaqZ0y5SvLiXZGMuAiTC/pub?w=704&h=575\" width=60%>"]},{"cell_type":"markdown","metadata":{"id":"Qc2kj5fMlxv3","colab_type":"text"},"source":["So here we need to encode our input sentence (for example), or in other words $c = embed (x)$. Simplest approach - get the mean of each word embeddings.\n","<br>\n","The decoded received the input sentence $s = Vc$\n","\n","As a result, out recurrent decoder will be as follows:\n","\n","$h_t = g(W[h_{t-1}; w_{t-1}] + s + b)$\n","\n","$u_t = Ph_t + b'$\n","\n","And thus, $P(W_t | x, w) = softmax(u_t)$\n","\n","Recall, unconditional RNN:\n","<br>\n","$h_t = g(W[h_{t-1}; w_{t-1}] + b)$"]},{"cell_type":"markdown","metadata":{"id":"VX50u_ePoTYp","colab_type":"text"},"source":["Typically, we need to find the most probably output given the input, i.e., $w^* = \\arg max p(w | x)$.\n","\n","Greedy search is used in such cases: beam search.\n","Where we preserve N softmax outputs, where N is the size of the beam."]},{"cell_type":"markdown","metadata":{"id":"iKAGkmotpyfg","colab_type":"text"},"source":["Potential issues and modification:\n","0. Does not care about the word order if we represent a sentence as a mean.\n","1. Previous architecture needs to store a lot of state to reproduce what is needed on the decoding step. We could try endocing the sequence backwards.\n","2. Gradients and memory cells will be eventually forgotten for long sequences. We could represent the embedding of the input and the outputs as matrices."]},{"cell_type":"markdown","metadata":{"id":"2yxJPI7kqvJf","colab_type":"text"},"source":["So the $embed(x)$ would be something like concatened internal states of the input rather than sum them up.\n","\n","Another approach: we could run the encoding step both forward and backword, stack the token representation together and then merge those into a matrix."]},{"cell_type":"markdown","metadata":{"id":"JazUz2LjcO5Z","colab_type":"text"},"source":["### Attention"]},{"cell_type":"markdown","metadata":{"id":"jzp851HhrUUQ","colab_type":"text"},"source":["Now having some smart/sophisticated representations of the input we can pass it all to the network.\n","<br>\n","Here at each output position $t$, TNN would receive two inputs (in addition to any recurrent inputs),\n","<br>\n","(1) previously generated output\n","<br>\n","(2) encoding of a view of the whole input matrix (weighted sum of the columns based on how important those at the current step - ATTENTION)."]},{"cell_type":"markdown","metadata":{"id":"1w9pEya4cX4q","colab_type":"text"},"source":["(c) [distill.pub](https://distill.pub/2016/augmented-rnns/#attentional-interfaces)\n","<br>\n","`The attention distribution is usually generated with content-based attention. The attending RNN generates a query describing what it wants to focus on. Each item is dot-producted with the query to produce a score, describing how well it matches the query. The scores are fed into a softmax to create the attention distribution.`\n","<br>\n","<img src=https://distill.pub/2016/augmented-rnns/assets/rnn_preview_ai.svg width=50%>"]},{"cell_type":"markdown","metadata":{"id":"1Ie-AEJIs5-F","colab_type":"text"},"source":["You can read up more on the attention models in the very intuitive explanations from Chris Dyer from\n","<br>DeepMind and his [presentation](http://lxmls.it.pt/2018/lxmls-dl3.pdf) at LxMLs 2018 in Lisbon."]},{"cell_type":"markdown","metadata":{"id":"Ed4lSkdEH9JR","colab_type":"text"},"source":["### Exercise"]},{"cell_type":"markdown","metadata":{"id":"JIRO4jI7Um3K","colab_type":"text"},"source":["Get inspired by the example [here](https://gist.github.com/siemanko/b18ce332bde37e156034e5d3f60f8a23).\n","\n","But first you might need to load the w2v model below."]},{"cell_type":"code","metadata":{"id":"3LyC7367GWCi","colab_type":"code","outputId":"a59843a4-dcef-464b-991b-b38d6a734959","executionInfo":{"status":"ok","timestamp":1560594532667,"user_tz":-120,"elapsed":23445,"user":{"displayName":"Julia Proskurnia","photoUrl":"https://lh4.googleusercontent.com/-Qke-0JLRMLo/AAAAAAAAAAI/AAAAAAAAIsM/X24zHBBNvWo/s64/photo.jpg","userId":"11878887336903611948"}},"colab":{"base_uri":"https://localhost:8080/","height":360}},"source":["#@title Data preparation and preprocessing { display-mode: \"form\" }\n","import pandas as pd\n","import nltk\n","import re\n","\n","!pip install --upgrade gensim\n","\n","# !wget http://nlp.stanford.edu/data/glove.6B.zip\n","# !unzip glove.6B.zip\n","\n","#    Note: it might take several minutes. Be patient!\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","\n","glove2word2vec(glove_input_file='glove.6B.50d.txt',\n","               word2vec_output_file=\"gensim_glove_vectors.txt\")\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: gensim in /usr/local/lib/python3.6/dist-packages (3.7.3)\n","Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n","Requirement already satisfied, skipping upgrade: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.4)\n","Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.4)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (2.21.0)\n","Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (1.9.165)\n","Requirement already satisfied, skipping upgrade: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (2019.3.9)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n","Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n","Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim) (0.2.1)\n","Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.4)\n","Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.165 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.165)\n","Requirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.165->boto3->smart-open>=1.7.0->gensim) (0.14)\n","Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.165->boto3->smart-open>=1.7.0->gensim) (2.5.3)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"bfqMiyhDsokF","colab_type":"code","outputId":"865aa7a9-368c-482a-f6fd-59182ba64174","executionInfo":{"status":"ok","timestamp":1560594574497,"user_tz":-120,"elapsed":1964,"user":{"displayName":"Julia Proskurnia","photoUrl":"https://lh4.googleusercontent.com/-Qke-0JLRMLo/AAAAAAAAAAI/AAAAAAAAIsM/X24zHBBNvWo/s64/photo.jpg","userId":"11878887336903611948"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import nltk\n","nltk.download('movie_reviews')\n","from nltk.corpus import movie_reviews\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import numpy as np\n","import random\n","import tensorflow as tf\n","import tensorflow.contrib.layers as layers\n","\n","map_fn = tf.map_fn\n","\n","from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","negative_ids = movie_reviews.fileids('neg')\n","positive_ids = movie_reviews.fileids('pos')\n","negative_reviews = [\n","    \" \".join(movie_reviews.words(fileids=[f])) \n","    for f in negative_ids\n","]\n","positive_reviews = [\n","    \" \".join(movie_reviews.words(fileids=[f])) \n","    for f in positive_ids\n","]\n","\n","texts = negative_reviews + positive_reviews\n","labels = np.array([0] * len(negative_reviews) + [1] * len(positive_reviews))\n","\n","from sklearn.utils import shuffle\n","texts, labels = shuffle(texts, labels, random_state=0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Package movie_reviews is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9FjSuYz0VWiY","colab_type":"code","colab":{}},"source":["# Prepare dataset here"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"by5cmzr3VMPs","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Dataset Preparation\n","import numpy as np\n","num_dimension = model.vector_size  # Get dimensionality out of the model.\n","document_embeddings = np.zeros((20, 2000, 50))\n","c = 0\n","for i, document in enumerate(texts):\n","  document_word_embeddings = \\\n","      np.array([model[token] for token in document if token in model])\n","  try:\n","    document_embeddings[:,i,:] = document_word_embeddings[:20, :]\n","  except Exception as e:\n","    c = c + 1\n","\n","input_labels = np.transpose(np.repeat(labels, 20).reshape((1, 2000, 20)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yL5NefS2VXCW","colab_type":"code","colab":{}},"source":["# Define the graph here"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"53I_z4gmyZgA","colab_type":"code","cellView":"both","outputId":"9ae3d0e0-c130-49ae-c5a7-e1c8d7c16d69","executionInfo":{"status":"ok","timestamp":1560594598899,"user_tz":-120,"elapsed":15747,"user":{"displayName":"Julia Proskurnia","photoUrl":"https://lh4.googleusercontent.com/-Qke-0JLRMLo/AAAAAAAAAAI/AAAAAAAAIsM/X24zHBBNvWo/s64/photo.jpg","userId":"11878887336903611948"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["#@title Graph Definition\n","################################################################################\n","##                           GRAPH DEFINITION                                 ##\n","################################################################################\n","\n","INPUT_SIZE    = 50       # embedding size of 50\n","RNN_HIDDEN    = 8\n","OUTPUT_SIZE   = 1       # positive or negative\n","TINY          = 1e-6    # to avoid NaNs in logs\n","LEARNING_RATE = 0.01\n","\n","USE_LSTM = True\n","\n","tf.reset_default_graph()\n","\n","inputs  = tf.placeholder(tf.float32, (None, None, INPUT_SIZE))  # (embedding, batch, in)\n","outputs = tf.placeholder(tf.float32, (None, None, OUTPUT_SIZE)) # (embedding, batch, out)\n","\n","cell = tf.nn.rnn_cell.BasicLSTMCell(RNN_HIDDEN, state_is_tuple=True)\n","\n","batch_size    = tf.shape(inputs)[1]\n","initial_state = cell.zero_state(batch_size, tf.float32)\n","\n","# Given inputs (time, batch, input_size) outputs a tuple\n","#  - outputs: (time, batch, output_size)\n","#  - states:  (time, batch, hidden_size)\n","rnn_outputs, rnn_states = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, time_major=True)\n","\n","final_projection = lambda x: layers.linear(x, num_outputs=OUTPUT_SIZE, activation_fn=tf.nn.sigmoid)\n","\n","predicted_outputs = map_fn(final_projection, rnn_outputs)\n","\n","error = -(outputs * tf.log(predicted_outputs + TINY) + (1.0 - outputs) * tf.log(1.0 - predicted_outputs + TINY))\n","error = tf.reduce_mean(error)\n","\n","train_fn = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(error)\n","\n","accuracy = tf.reduce_mean(tf.cast(tf.abs(outputs - predicted_outputs) < 0.5, tf.float32))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0615 10:29:57.034386 140029374015360 deprecation.py:323] From <ipython-input-6-370d0e046f38>:15: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","W0615 10:29:57.067802 140029374015360 deprecation.py:323] From <ipython-input-6-370d0e046f38>:23: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","W0615 10:29:57.131539 140029374015360 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0615 10:29:57.145892 140029374015360 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9EmwM9OoVXj9","colab_type":"code","colab":{}},"source":["# Write your training loop here"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGbyF0voIB_f","colab_type":"code","cellView":"both","outputId":"d0e13432-df54-473a-a1db-75ae1e898fc8","executionInfo":{"status":"ok","timestamp":1560594825270,"user_tz":-120,"elapsed":186850,"user":{"displayName":"Julia Proskurnia","photoUrl":"https://lh4.googleusercontent.com/-Qke-0JLRMLo/AAAAAAAAAAI/AAAAAAAAIsM/X24zHBBNvWo/s64/photo.jpg","userId":"11878887336903611948"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#@title Training Loop\n","NUM_WORDS = 20\n","TRAINING_SIZE = 1200\n","BATCH_SIZE = 5\n","ITERATIONS_PER_EPOCH = int( TRAINING_SIZE / BATCH_SIZE )\n","\n","valid_x = document_embeddings[:, TRAINING_SIZE:2000, :]\n","valid_y = input_labels[:, TRAINING_SIZE:2000, :]\n","\n","session = tf.Session()\n","session.run(tf.global_variables_initializer())\n","\n","for epoch in range(100):\n","    epoch_error = 0\n","    for i in range(ITERATIONS_PER_EPOCH):\n","        x = document_embeddings[:, i*BATCH_SIZE : i+BATCH_SIZE*(i+1), :]\n","        y = input_labels[:, i*BATCH_SIZE : i+BATCH_SIZE*(i+1), :]\n","        epoch_error += session.run([error, train_fn], {\n","            inputs: x,\n","            outputs: y,\n","        })[0]\n","    epoch_error /= ITERATIONS_PER_EPOCH\n","    valid_accuracy = session.run(accuracy, {\n","        inputs:  valid_x,\n","        outputs: valid_y,\n","    })\n","    if epoch % 10 == 0:\n","        print (\"Epoch %d, train error: %.2f, valid accuracy: %.1f %%\" % (epoch, epoch_error, valid_accuracy * 100.0))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 0, train error: 0.69, valid accuracy: 50.4 %\n","Epoch 10, train error: 0.69, valid accuracy: 49.4 %\n","Epoch 20, train error: 0.69, valid accuracy: 50.8 %\n","Epoch 30, train error: 0.68, valid accuracy: 51.3 %\n","Epoch 40, train error: 0.66, valid accuracy: 51.2 %\n","Epoch 50, train error: 0.66, valid accuracy: 50.5 %\n","Epoch 60, train error: 0.65, valid accuracy: 50.6 %\n","Epoch 70, train error: 0.64, valid accuracy: 50.8 %\n","Epoch 80, train error: 0.63, valid accuracy: 51.7 %\n","Epoch 90, train error: 0.62, valid accuracy: 51.5 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vh_TisuOcOxA","colab_type":"text"},"source":["## Convolutation Neural Network"]},{"cell_type":"markdown","metadata":{"id":"zWN7caWqcXUL","colab_type":"text"},"source":["Initially convolutions as part of the neural networks was used in the context of images.\n","<br>\n","Even without any machine learning, for images were found that *filters* could emphasize one or another property of the image.\n","<br>Convolutation is simply an element-wise multiplication of two matrices followed by a sum.\n","\n","Typically convolution can be seen as follows:\n","<br>\n","<img src=\"http://cs231n.github.io/assets/cnn/depthcol.jpeg\" width=50%>\n","<br>\n","<img src=\"https://www.pyimagesearch.com/wp-content/uploads/2016/06/convolutions_kernel_sliding.jpg\" width=30%>\n"," (image produced by Adrian Rosebrock [here](https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/))\n","\n","\n","([c](http://cs231n.github.io/convolutional-networks/)) `Each neuron in the convolutional layer is connected only to a local region in the input volume spatially, but to the full depth (i.e. all color channels). Note, there are multiple neurons (5 in this example) along the depth, all looking at the same region in the input - see discussion of depth columns in text below.`\n","\n","A great [animation](https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/) of the multidimentional convolution in practice:\n","<img src=\"https://deeplearning4j.org/img/karpathy-convnet-labels.png\" width=60%>\n","\n","In particular, linear filters were shown to highlight vertical or horizontal borders of the picture (more details [here](http://cs231n.github.io/convolutional-networks/)).\n","<img src=\"http://cs231n.github.io/assets/cnn/weights.jpeg\" width=50%>\n","\n","Read more on the convolutation in the math world [here](https://deeplearning4j.org/convolutionalnetwork#define)."]},{"cell_type":"markdown","metadata":{"id":"8Ec0vXdS7PQl","colab_type":"text"},"source":["### Source http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow"]},{"cell_type":"markdown","metadata":{"id":"l99V5UWuA6GK","colab_type":"text"},"source":["<img src=\"http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM.png\" width=60%>"]},{"cell_type":"code","metadata":{"id":"FRRz-Su10OJH","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Imports\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import time\n","import datetime\n","import re\n","from tensorflow.contrib import learn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJ_0tVdj1pPj","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Flags\n","flags = tf.app.flags \n","FLAGS = flags.FLAGS\n","\n","tf.app.flags.DEFINE_string('f', '', 'kernel')\n","\n","# Data loading params\n","flags.DEFINE_float(\"dev_sample_percentage\", .1, \"Percentage of the training data to use for validation\")\n","flags.DEFINE_string(\"positive_data_file\", \"rt-polarity.pos\", \"Data source for the positive data.\")\n","flags.DEFINE_string(\"negative_data_file\", \"rt-polarity.neg\", \"Data source for the negative data.\")\n","\n","# Model Hyperparameters\n","flags.DEFINE_integer(\"embedding_dim\", 128, \"Dimensionality of character embedding (default: 128)\")\n","flags.DEFINE_string(\"filter_sizes\", \"3,4,5\", \"Comma-separated filter sizes (default: '3,4,5')\")\n","flags.DEFINE_integer(\"num_filters\", 128, \"Number of filters per filter size (default: 128)\")\n","flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n","flags.DEFINE_float(\"l2_reg_lambda\", 0.0, \"L2 regularization lambda (default: 0.0)\")\n","\n","# # Training parameters\n","flags.DEFINE_integer(\"batch_size\", 64, \"Batch Size (default: 64)\")\n","flags.DEFINE_integer(\"num_epochs\", 200, \"Number of training epochs (default: 200)\")\n","flags.DEFINE_integer(\"evaluate_every\", 100, \"Evaluate model on dev set after this many steps (default: 100)\")\n","flags.DEFINE_integer(\"checkpoint_every\", 100, \"Save model after this many steps (default: 100)\")\n","flags.DEFINE_integer(\"num_checkpoints\", 5, \"Number of checkpoints to store (default: 5)\")\n","# # Misc Parameters\n","flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n","flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n","\n","FLAGS = flags.FLAGS"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lozUgDKnsg-R","colab_type":"code","cellView":"form","colab":{}},"source":["#@title TextCNN\n","import tensorflow as tf\n","import numpy as np\n"," \n","class TextCNN(object):\n","    \"\"\"\n","    A CNN for text classification.\n","    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n","    \"\"\"\n","    def __init__(\n","      self,\n","        sequence_length, # The length of our sentences. Remember that we padded\n","        # all our sentences to have the same length (59 for our data set).\n","        num_classes, # Number of classes in the output layer,\n","        # two in our case (positive and negative).\n","        vocab_size, # The size of our vocabulary. This is needed to define the\n","        #size of our embedding layer, which will have shape\n","        #[vocabulary_size, embedding_size].\n","        embedding_size, # The dimensionality of our embeddings.\n","        filter_sizes, #  The number of words we want our convolutional filters\n","        # to cover. We will have num_filters for each size specified here.\n","        # For example, [3, 4, 5] means that we will have filters that slide over\n","        # 3, 4 and 5 words respectively, for a total of 3 * num_filters filters.\n","        num_filters, # The number of filters per filter size \n","        l2_reg_lambda=0.0\n","    ):\n","      \n","      # Placeholders for input, output and dropout\n","      # tf.placeholder creates a placeholder variable that we feed to the network\n","      # when we execute it at train or test time. The second argument is the shape\n","      # of the input tensor. None means that the length of that dimension could be\n","      # anything.\n","      self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n","      self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n","      self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n","      \n","      # Keeping track of l2 regularization loss (optional)\n","      l2_loss = tf.constant(0.0)\n","    \n","      # tf.device(\"/cpu:0\") forces an operation to be executed on the CPU.\n","      with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n","        # W is our embedding matrix that we learn during training.\n","        # We initialize it using a random uniform distribution.\n","        # tf.nn.embedding_lookup creates the actual embedding operation.\n","        W = tf.Variable(\n","            tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n","            name=\"W\")\n","        # Result of embedding_lookup is 3-dimensional tensor of shape\n","        # [None, sequence_length, embedding_size].\n","        self.embedded_chars = tf.nn.embedding_lookup(W, self.input_x)\n","        self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n","\n","      \n","      pooled_outputs = []\n","      for i, filter_size in enumerate(filter_sizes):\n","        with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n","          # Convolution Layer\n","          filter_shape = [filter_size, embedding_size, 1, num_filters]\n","          # W is our filter matrix\n","          W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n","          b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n","          conv = tf.nn.conv2d(\n","            self.embedded_chars_expanded,\n","            W,\n","            strides=[1, 1, 1, 1],\n","            padding='VALID', # slide the filter over our sentence without\n","            # padding the edges, performing a narrow convolution that gives\n","            # us an output of shape [1, sequence_length - filter_size + 1, 1, 1]\n","            name=\"conv\")\n","          # Apply nonlinearity\n","          # h is the result of applying the nonlinearity to the convolution output\n","          h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n","          # Max-pooling over the outputs\n","          # Result [batch_size, 1, 1, num_filters]\n","          #  where last dimension corresponds to our features.\n","          pooled = tf.nn.max_pool(\n","            h,\n","            ksize=[1, sequence_length - filter_size + 1, 1, 1],\n","            strides=[1, 1, 1, 1],\n","            padding='VALID',\n","            name=\"pool\")\n","          pooled_outputs.append(pooled)\n","\n","      # Combine all the pooled features\n","      num_filters_total = num_filters * len(filter_sizes)\n","      # [batch_size, num_filters_total]\n","      self.h_pool = tf.concat(pooled_outputs, 3)\n","      # Using -1 in tf.reshape tells TensorFlow to flatten the dimension when possible.\n","      self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n","    \n","      # Add dropout\n","      with tf.name_scope(\"dropout\"):\n","        # The fraction of neurons we keep enabled is defined by the dropout_keep_prob input to our network. \n","        self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n","\n","      with tf.name_scope(\"output\"):\n","        W = tf.Variable(tf.truncated_normal([num_filters_total, num_classes], stddev=0.1), name=\"W\")\n","        b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n","        l2_loss += tf.nn.l2_loss(W)\n","        l2_loss += tf.nn.l2_loss(b)\n","        self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n","        self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n","\n","      # Calculate mean cross-entropy loss (http://cs231n.github.io/linear-classify/#softmax)\n","        with tf.name_scope(\"loss\"):\n","            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n","            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n","\n","      # Calculate Accuracy\n","      with tf.name_scope(\"accuracy\"):\n","        correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n","        self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XHj6bBHyS72","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Training function\n","def train(x_train, y_train, vocab_processor, x_dev, y_dev):\n","  # A Session is the environment you are executing graph operations in, and it\n","  # contains state about Variables and queues. Each session operates on a single graph.\n","  # A Graph contains operations and tensors.\n","  # You can use the same graph in multiple sessions, but not multiple graphs in one session.\n","  with tf.Graph().as_default():\n","    session_conf = tf.ConfigProto(\n","      allow_soft_placement=FLAGS.allow_soft_placement,\n","      log_device_placement=FLAGS.log_device_placement)\n","    sess = tf.Session(config=session_conf)\n","    with sess.as_default():\n","        cnn = TextCNN(\n","            sequence_length=x_train.shape[1],\n","            num_classes=y_train.shape[1],\n","            vocab_size=len(vocab_processor.vocabulary_),\n","            embedding_size=FLAGS.embedding_dim,\n","            filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n","            num_filters=FLAGS.num_filters,\n","            l2_reg_lambda=FLAGS.l2_reg_lambda)\n","\n","        # Define Training procedure\n","        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n","        optimizer = tf.train.AdamOptimizer(1e-3)\n","        grads_and_vars = optimizer.compute_gradients(cnn.loss)\n","        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n","\n","        # Keep track of gradient values and sparsity (optional)\n","        grad_summaries = []\n","        for g, v in grads_and_vars:\n","            if g is not None:\n","                grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n","                sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n","                grad_summaries.append(grad_hist_summary)\n","                grad_summaries.append(sparsity_summary)\n","        grad_summaries_merged = tf.summary.merge(grad_summaries)\n","\n","        # Output directory for models and summaries\n","        timestamp = str(int(time.time()))\n","        out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n","        print(\"Writing to {}\\n\".format(out_dir))\n","\n","        # Summaries for loss and accuracy\n","        loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n","        acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n","\n","        # Train Summaries\n","        train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n","        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n","        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n","\n","        # Dev summaries\n","        dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n","        dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n","        dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)\n","\n","        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n","        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n","        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n","        if not os.path.exists(checkpoint_dir):\n","            os.makedirs(checkpoint_dir)\n","        saver = tf.train.Saver(tf.global_variables(), max_to_keep=FLAGS.num_checkpoints)\n","\n","        # Write vocabulary\n","        vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n","\n","        # Initialize all variables\n","        sess.run(tf.global_variables_initializer())\n","\n","        def train_step(x_batch, y_batch):\n","            \"\"\"\n","            A single training step\n","            \"\"\"\n","            feed_dict = {\n","              cnn.input_x: x_batch,\n","              cnn.input_y: y_batch,\n","              cnn.dropout_keep_prob: FLAGS.dropout_keep_prob\n","            }\n","            _, step, summaries, loss, accuracy = sess.run(\n","                [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],\n","                feed_dict)\n","            time_str = datetime.datetime.now().isoformat()\n","            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n","            train_summary_writer.add_summary(summaries, step)\n","\n","        def dev_step(x_batch, y_batch, writer=None):\n","            \"\"\"\n","            Evaluates model on a dev set\n","            \"\"\"\n","            feed_dict = {\n","              cnn.input_x: x_batch,\n","              cnn.input_y: y_batch,\n","              cnn.dropout_keep_prob: 1.0\n","            }\n","            step, summaries, loss, accuracy = sess.run(\n","                [global_step, dev_summary_op, cnn.loss, cnn.accuracy],\n","                feed_dict)\n","            time_str = datetime.datetime.now().isoformat()\n","            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n","            if writer:\n","                writer.add_summary(summaries, step)\n","                \n","        def batch_iter(data, batch_size, num_epochs, shuffle=True):\n","          \"\"\"\n","          Generates a batch iterator for a dataset.\n","          \"\"\"\n","          data = np.array(data)\n","          data_size = len(data)\n","          num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n","          for epoch in range(num_epochs):\n","              # Shuffle the data at each epoch\n","              if shuffle:\n","                  shuffle_indices = np.random.permutation(np.arange(data_size))\n","                  shuffled_data = data[shuffle_indices]\n","              else:\n","                  shuffled_data = data\n","              for batch_num in range(num_batches_per_epoch):\n","                  start_index = batch_num * batch_size\n","                  end_index = min((batch_num + 1) * batch_size, data_size)\n","                  yield shuffled_data[start_index:end_index]\n","\n","        # Generate batches\n","        batches = batch_iter(\n","            list(zip(x_train, y_train)), FLAGS.batch_size, FLAGS.num_epochs)\n","        # Training loop. For each batch...\n","        for batch in batches:\n","            x_batch, y_batch = zip(*batch)\n","            train_step(x_batch, y_batch)\n","            current_step = tf.train.global_step(sess, global_step)\n","            if current_step % FLAGS.evaluate_every == 0:\n","                print(\"\\nEvaluation:\")\n","                dev_step(x_dev, y_dev, writer=dev_summary_writer)\n","                print(\"\")\n","            if current_step % FLAGS.checkpoint_every == 0:\n","                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n","                print(\"Saved model checkpoint to {}\\n\".format(path))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4g5a8I2hzuza","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Preprocessing\n","def clean_str(string):\n","    \"\"\"\n","    Tokenization/string cleaning for all datasets except for SST.\n","    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n","    \"\"\"\n","    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n","    string = re.sub(r\"\\'s\", \" \\'s\", string)\n","    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n","    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n","    string = re.sub(r\"\\'re\", \" \\'re\", string)\n","    string = re.sub(r\"\\'d\", \" \\'d\", string)\n","    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n","    string = re.sub(r\",\", \" , \", string)\n","    string = re.sub(r\"!\", \" ! \", string)\n","    string = re.sub(r\"\\(\", \" \\( \", string)\n","    string = re.sub(r\"\\)\", \" \\) \", string)\n","    string = re.sub(r\"\\?\", \" \\? \", string)\n","    string = re.sub(r\"\\s{2,}\", \" \", string)\n","    return string.strip().lower()\n","\n","def load_data_and_labels(positive_data_file, negative_data_file):\n","    \"\"\"\n","    Loads MR polarity data from files, splits the data into words and generates labels.\n","    Returns split sentences and labels.\n","    \"\"\"\n","    # Load data from files\n","    positive_examples = list(open(positive_data_file, \"r\", encoding='utf-8').readlines())\n","    positive_examples = [s.strip() for s in positive_examples]\n","    negative_examples = list(open(negative_data_file, \"r\", encoding='utf-8').readlines())\n","    negative_examples = [s.strip() for s in negative_examples]\n","    # Split by words\n","    x_text = positive_examples + negative_examples\n","    x_text = [clean_str(sent) for sent in x_text]\n","    # Generate labels\n","    positive_labels = [[0, 1] for _ in positive_examples]\n","    negative_labels = [[1, 0] for _ in negative_examples]\n","    y = np.concatenate([positive_labels, negative_labels], 0)\n","    return [x_text, y]\n","\n","def preprocess():\n","    # Data Preparation\n","    # ==================================================\n","\n","    # Load data\n","    print(\"Loading data...\")\n","    x_text, y = load_data_and_labels(FLAGS.positive_data_file, FLAGS.negative_data_file)\n","\n","    # Build vocabulary\n","    max_document_length = max([len(x.split(\" \")) for x in x_text])\n","    vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n","    x = np.array(list(vocab_processor.fit_transform(x_text)))\n","\n","    # Randomly shuffle data\n","    np.random.seed(10)\n","    shuffle_indices = np.random.permutation(np.arange(len(y)))\n","    x_shuffled = x[shuffle_indices]\n","    y_shuffled = y[shuffle_indices]\n","\n","    # Split train/test set\n","    dev_sample_index = -1 * int(FLAGS.dev_sample_percentage * float(len(y)))\n","    x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n","    y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n","\n","    del x, y, x_shuffled, y_shuffled\n","\n","    print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n","    print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))\n","    return x_train, y_train, vocab_processor, x_dev, y_dev"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7N5jXzHX0mTc","colab_type":"code","outputId":"94dc0d43-f993-4a32-ffbd-516de951ae5d","executionInfo":{"status":"ok","timestamp":1563695220274,"user_tz":-120,"elapsed":8385,"user":{"displayName":"Julia Proskurnia","photoUrl":"https://lh4.googleusercontent.com/-Qke-0JLRMLo/AAAAAAAAAAI/AAAAAAAAIsM/X24zHBBNvWo/s64/photo.jpg","userId":"11878887336903611948"}},"colab":{"base_uri":"https://localhost:8080/","height":411}},"source":["!wget https://github.com/dennybritz/cnn-text-classification-tf/blob/master/data/rt-polaritydata/rt-polarity.neg\n","!wget https://github.com/dennybritz/cnn-text-classification-tf/blob/master/data/rt-polaritydata/rt-polarity.pos"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-07-21 07:46:52--  https://github.com/dennybritz/cnn-text-classification-tf/blob/master/data/rt-polaritydata/rt-polarity.neg\n","Resolving github.com (github.com)... 192.30.253.113\n","Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: rt-polarity.neg\n","\n","rt-polarity.neg         [ <=>                ]   1.59M  --.-KB/s    in 0.09s   \n","\n","2019-07-21 07:46:58 (17.9 MB/s) - rt-polarity.neg saved [1672916]\n","\n","--2019-07-21 07:46:59--  https://github.com/dennybritz/cnn-text-classification-tf/blob/master/data/rt-polaritydata/rt-polarity.pos\n","Resolving github.com (github.com)... 192.30.253.113\n","Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: rt-polarity.pos\n","\n","rt-polarity.pos         [ <=>                ]   1.61M  --.-KB/s    in 0.09s   \n","\n","2019-07-21 07:46:59 (17.7 MB/s) - rt-polarity.pos saved [1685444]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6HZgnHfUzC2L","colab_type":"code","outputId":"be427707-3a4c-4282-a1a7-e39d2c4cc971","executionInfo":{"status":"ok","timestamp":1563695226909,"user_tz":-120,"elapsed":3397,"user":{"displayName":"Julia Proskurnia","photoUrl":"https://lh4.googleusercontent.com/-Qke-0JLRMLo/AAAAAAAAAAI/AAAAAAAAIsM/X24zHBBNvWo/s64/photo.jpg","userId":"11878887336903611948"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["x_train, y_train, vocab_processor, x_dev, y_dev = preprocess()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading data...\n"],"name":"stdout"},{"output_type":"stream","text":["W0721 07:47:05.210405 140372627502976 deprecation.py:323] From <ipython-input-5-ae7cd7e93c1f>:50: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","W0721 07:47:05.213084 140372627502976 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","W0721 07:47:05.216866 140372627502976 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n"],"name":"stderr"},{"output_type":"stream","text":["Vocabulary Size: 34838\n","Train/Dev split: 39978/4441\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"25QmcsZj12fR","colab_type":"code","colab":{}},"source":["train(x_train, y_train, vocab_processor, x_dev, y_dev)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4wsMmYiud6MG","colab_type":"text"},"source":["## Misc"]},{"cell_type":"markdown","metadata":{"id":"cxLkEoLQd8Hc","colab_type":"text"},"source":["* [GAN](https://arxiv.org/abs/1406.2661) and nice explanation of [GANs](https://deeplearning4j.org/generative-adversarial-network)\n","  * [MaskGan](https://arxiv.org/abs/1801.07736)\n","  * [Wasserstein GAN](https://arxiv.org/abs/1701.07875)\n","* [Capsule Networks](https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b)\n","<br>\n","If you want to know more about the capsule nets and how exactly they became possible only now - read the initial two papers\n","<br>by [Hinton et al.](https://openreview.net/pdf?id=HJWLfGWRb) and [Sabour et al.](https://arxiv.org/pdf/1710.09829.pdf)\n"]},{"cell_type":"markdown","metadata":{"id":"BZSGnoCFcdgk","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"fmitJ6K9vlCU","colab_type":"text"},"source":["## More advanced metrics"]},{"cell_type":"markdown","metadata":{"id":"r86_ESvGvrx-","colab_type":"text"},"source":["### [Text Simplification](https://docs.google.com/presentation/d/1niuedwfJ4n7cG7rKxFq6qHchkFCAyv4biSHrxzXImIg/edit#slide=id.p)\n"]},{"cell_type":"markdown","metadata":{"id":"6FIuf47ud4oQ","colab_type":"text"},"source":["# [Smart Reply Journey](https://ai.googleblog.com/2015/11/computer-respond-to-this-email.html)\n","\n","[Preso](https://docs.google.com/presentation/d/114LMqq1-IemD7jGNq5eIVn5PRa3aKIAFm9g3k2LSjfc/edit?ts=5b4b93a3)"]},{"cell_type":"markdown","metadata":{"id":"wemv3rbtOeIN","colab_type":"text"},"source":["---"]}]}