{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Definition\n",
    "\n",
    "Hyper-parameters control the fitting behavior and are not learned from data.\n",
    "\n",
    "```\n",
    "estimator.get_params()\n",
    "```\n",
    "\n",
    "If you think of your estimator as a black-box, hyper-parameters are knobs on the outside of the box.\n",
    "The goal of *hyper-parameter tuning* is to set the nobs to get optimal performance.\n",
    "\n",
    "<img src=\"img/hp-tuning-two-knobs.jpg\">\n",
    "<div style=\"text-align: right\">Source: Wikipedia</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why hyper-parameters?\n",
    "\n",
    "HPs control the fitting behavior thus they \"guide\" the model search. You can think of this guidance as injecting *bias* into the model. \n",
    "\n",
    "<img src=\"img/eslii-mdl-search.png\" style=\"width:400px;\">\n",
    "<div style=\"text-align: right\">Source: T. Hastie et al. (2017) \"Elements of Statistical Learning (Ed. 2)\"</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Examples\n",
    "\n",
    "`sklearn.svm.SVC`\n",
    "  * C ... complexity, higher C means more variance can be captured.\n",
    "  * gamma ... width of the RBF kernerl, higher means more smoothness bias.\n",
    "  \n",
    "`sklearn.ensemble.RandomForestClassifier`\n",
    "  * max_depth ... the deeper the trees the more variance we can capture.\n",
    "  * n_features ... the more de-correlated trees, the more variance reduction (but the more trees needed).\n",
    "  \n",
    "`sklearn.linear_model.Ridge`\n",
    "  * alpha ... penalty on the L2 norm of the model coefficients, higher alpha more bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyper-parameter Tuning\n",
    "\n",
    "*Grid Search* \n",
    "\n",
    "    Defacto standard method for tuning hyper-parameters in the past decades.\n",
    "    \n",
    "    \n",
    "*Random Search*\n",
    "\n",
    "    Explore the hyper-parameter space randomly by drawing samples. \n",
    "    Good for high-dimensional spaces (e.g. DNN).\n",
    "    \n",
    "    \n",
    "<img src=\"img/bergstra12-grid-vs-rand.png\" style=\"width:600px;\">\n",
    "<div style=\"text-align: right\">Source: J. Bergstra and Y. Bengio (2012) \"Random Search for Hyper-Parameter Optimization\"</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When is Grid Search not a good fit?\n",
    "<img src=\"img/hp-tuning-many-knobs.jpg\" >\n",
    "<div style=\"text-align: right\">Source: Wikipedia</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyper-parameter Tuning in Scikit-learn\n",
    "\n",
    "A search consists of:\n",
    "\n",
    "  * an estimator (regressor or classifier such as `sklearn.svm.SVC()`);\n",
    "  * a parameter space (e.g. `{'gamma': [0.01, 0.1, 1.0]}`);\n",
    "  * a method for searching or sampling candidates;\n",
    "  * a cross-validation scheme; and\n",
    "  * a score function (e.g. `sklearn.metrics.accuracy_score`).\n",
    "  \n",
    "## Classes\n",
    "\n",
    "  * `GridSearchCV`\n",
    "  * `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description\n",
      "----------\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n",
      "model score: 4.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyned/anaconda3/envs/ucu/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "data = load_boston()\n",
    "print(\"Description\\n{}\\n{}\".format('-' * 10, data.DESCR))\n",
    "X = data.data\n",
    "y = data.target\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "est = SVR()\n",
    "\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "print(\"model score: %.3f\" % mean_absolute_error(y_test, est.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "model score: 3.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    0.3s finished\n",
      "/home/cyned/anaconda3/envs/ucu/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "est = SVR()\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [0.1, 1, 10, 100], 'kernel': ['linear']},\n",
    "  {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 0.01], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "gs = GridSearchCV(est, param_grid, cv=3, scoring='neg_mean_absolute_error', verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"best params: {}\".format(gs.best_params_))\n",
    "print(\"model score: %.3f\" % mean_absolute_error(y_test, gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'C': 49.88720138545616, 'gamma': 0.18083692319941533, 'kernel': 'rbf'}\n",
      "model score: 2.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "est = SVR()\n",
    "\n",
    "param_grid = {\n",
    "    'C': scipy.stats.expon(scale=100), \n",
    "    'gamma': scipy.stats.expon(scale=.1), \n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "gs = RandomizedSearchCV(est, param_grid, cv=3, scoring='neg_mean_absolute_error', \n",
    "                        n_iter=12, verbose=1, random_state=0)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"best params: {}\".format(gs.best_params_))\n",
    "print(\"model score: %.3f\" % mean_absolute_error(y_test, gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import scipy\n",
    "dist = scipy.stats.expon(scale=100)\n",
    "_ = plt.hist(dist.rvs(1000), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tuning Shortcuts\n",
    "\n",
    "### Fit-once-evaluate-many\n",
    "\n",
    "Some models allow us to evaluate many hyper-parameter settings in a single fit. \n",
    "Examples: n_estimators in `RandomForest` and `GradientBoosting`; \"regularization path\" in linear models.\n",
    "    \n",
    "### Warm-starts\n",
    "\n",
    "Some models converge faster when warm started from a previous solution (with different HP settings). See [warm_start](https://scikit-learn.org/stable/glossary.html#term-warm-start) in sklearn.\n",
    "    \n",
    "### Heuristics\n",
    "\n",
    "For some hyper-parameters, good values or ranges can be compute via heuristics.\n",
    "Example: `gamma='auto'` in RBF kernel. \n",
    "    \n",
    "### Sub-sampling\n",
    "\n",
    "For some hyper-parameters, we can probe for good values on a subset of the data. Be cautious though!\n",
    "Example: `learning_rate` in SGD."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
